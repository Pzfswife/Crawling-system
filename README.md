## 项目简介
项目旨在开发一个高效、稳定且具备一定反爬能力的爬虫程序，从中国知网（CNKI）网站上爬取与特定关键词相关的论文信息，如论文的标题、作者、来源、发表时间等，并将这些数据存储到 Redis 数据库中，以便后续的数据分析、处理和挖掘。同时，项目使用 Flink 对数据进行实时处理，并将最终数据存储到 Hadoop HDFS 中。

## 环境要求
- Java 8
- Flink 1.18.1
- Redis 6.2.3
- Hadoop 3.4.1

## 项目结构
- `src/main/java`：主要的 Java 代码
- `src/main/resources`：配置文件
- `src/test/java`：单元测试代码
- `src/test/resources`：测试配置文件
- `pom.xml`：Maven 依赖管理文件

## 使用方法
1. 确保 Redis、Hadoop 和 Flink 服务已启动。
2. 运行 `App.java` 启动爬虫和 Flink 处理程序。
3. 爬取的数据将通过 Flink 处理并输出。

## 注意事项
- 合法性：在爬取知网数据时，一定要遵守知网的 robots.txt 协议和相关法律法规，确保爬取行为的合法性。
- 页面结构变化：知网的页面结构可能会随时变化，需要定期检查和调整选择器，以保证数据的正确解析。
